{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music generation RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "vWdBlvm-_XUZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Music Generation with an LSTM Network\n",
        "\n",
        "**You will learn to:**\n",
        "- Apply an LSTM to music generation.\n",
        "- Generate your own jazz music with deep learning.\n",
        "\n",
        "Please run the following cell to load all the packages required in this assignment."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1wcS9VJ1_9xU",
        "outputId": "34b2d86c-5776-4894-f1d5-cee7cd4b5fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Option_AI_2nd/ML/TP6 Music Generation RNN todo/P2 LSTM Network')\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Option_AI_2nd/ML/TP6 Music Generation RNN todo/P2 LSTM Network\n",
            " data\t\t inference_code.py\t       music_utils.py   qa.py\n",
            " data_utils.py\t jazz_improv.py\t\t       output\t        tune1.midi\n",
            " grammar.py\t midi.py\t\t       preprocess.py\n",
            " images\t\t'Music generation RNN.ipynb'   __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pwOgouFO_XUb",
        "outputId": "6983d81a-0e20-4865-8862-576cc0bd578a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import IPython\n",
        "import sys\n",
        "from music21 import *\n",
        "import numpy as np\n",
        "from grammar import *\n",
        "from qa import *\n",
        "from preprocess import * \n",
        "from music_utils import *\n",
        "from data_utils import *\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from IPython.display import Image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IiT47_5b_XUh"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 - Problem statement\n",
        "\n",
        "\n",
        "You will train a network to generate novel jazz solos in a style representative of a body of performed work.\n",
        "\n",
        "\n",
        "### 1.1 - Dataset\n",
        "\n",
        "You will train your algorithm on a corpus of Jazz music. **You can listen directly the audio file \"30s_seq.mp3\" in the \"data\" folder.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ObWhNsD4_XUm"
      },
      "cell_type": "markdown",
      "source": [
        "The musical data was rendered to terms of musical \"values.\" You can informally think of each \"value\" as a note, which comprises a pitch and a duration. For the purpose of this exercice, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. \n",
        "\n",
        "Our music generation system will use 78 unique values."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "y2nupoEz_XUn",
        "outputId": "0c00222d-d595-40d4-a3f9-b2134f5e3faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "X, Y, n_values, indices_values = load_music_utils()\n",
        "print('shape of X:', X.shape)\n",
        "print('number of training examples:', X.shape[0])\n",
        "print('Tx (length of sequence):', X.shape[1])\n",
        "print('total # of unique values:', n_values)\n",
        "print('Shape of Y:', Y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X: (60, 30, 78)\n",
            "number of training examples: 60\n",
            "Tx (length of sequence): 30\n",
            "total # of unique values: 78\n",
            "Shape of Y: (30, 60, 78)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zexqmISR_XUq"
      },
      "cell_type": "markdown",
      "source": [
        "You have just loaded the following:\n",
        "\n",
        "- `X`: This is an (m, $T_x$, 78) dimensional array. We have m training examples, each of which is a snippet of $T_x =30$ musical values. At each time step, the input is one of 78 different possible values, represented as a one-hot vector. Thus for example, X[i,t,:] is a one-hot vector representating the value of the i-th example at time t. \n",
        "\n",
        "- `Y`: This is essentially the same as `X`, but shifted one step to the left (to the past). We're interested in the network using the previous values to predict the next value, so our sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$. However, the data in `Y` is reordered to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed to the LSTM later. \n",
        "\n",
        "- `n_values`: The number of unique values in this dataset. This should be 78. \n",
        "\n",
        "- `indices_values`: python dictionary mapping from 0-77 to musical values."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ojZqAu89_XUr"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 - Overview of our model\n",
        "\n",
        "Here is the architecture of the model we will use.\n",
        "\n",
        "<!--\n",
        "<img src=\"images/djmodel.png\" style=\"width:600;height:400px;\">\n",
        "<br>\n",
        "<caption><center> **Figure 1**: LSTM model. $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, ..., x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\\langle t \\rangle}$ is an index corresponding to a value (ex: \"A,0.250,< m2,P-4 >\") while $\\hat{y}$ is the prediction for the next value  </center></caption>\n",
        "!--> \n",
        "\n",
        "We will be training the model on random snippets of 30 values taken from a much longer piece of music. We are setting each of the snippts to have the same length $T_x = 30$ to make vectorization easier. \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "svRNcLdM8aw-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(\"images/music_generation.png\",width=900,height=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uUy_39G0_XUs"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 - Building the model\n",
        "\n",
        "You will build and train a model that will learn musical patterns. You will need to build a model that takes in X of shape $(m, T_x, 78)$ and Y of shape $(T_y, m, 78)$. We will use an LSTM with 64 dimensional hidden states. Lets set `n_a = 64`. \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zFBSdZoq_XUs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_a = 64 \n",
        "n_values=78"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "x7rtXBaC_XUu"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here's how you can create a Keras model with multiple inputs and outputs. For sequence generation, at test time we don't know all the values of $x^{\\langle t\\rangle}$ in advance; instead we generate them one at a time using $x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$ and you'll need to implement your own for-loop to iterate over the different time steps. \n",
        "\n",
        "The function `djmodel()` will call the LSTM layer $T_x$ times using a for-loop. Important: $T_x$ copies have the same weights (it should not re-initiaiize the weights every time).\n",
        "The key steps for implementing layers with shareable weights in Keras are: \n",
        "1. Define the layer objects (use global variables).\n",
        "2. Call these objects when propagating the input.\n",
        "\n",
        "Please check the Keras documentation to make sure you understand what these layers are: [Reshape()](https://keras.io/layers/core/#reshape), [LSTM()](https://keras.io/layers/recurrent/#lstm), [Dense()](https://keras.io/layers/core/#dense).\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gKWCrpCS_XUu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reshapor = Reshape((1, 78))                        # Used in Step 2.B of djmodel(), below\n",
        "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
        "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7nhC1B0L_XUw"
      },
      "cell_type": "markdown",
      "source": [
        "To propagate a Keras tensor object X through one of these layers, use `layer_object(X)` (or `layer_object([X,Y])` if it requires multiple inputs.). For example, `reshapor(X)` will propagate X through the `Reshape((1,78))` layer defined above."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yWT8BrXW_XUx"
      },
      "cell_type": "markdown",
      "source": [
        " \n",
        "**Exercise**: Implement `djmodel()`. You will need to carry out 2 steps:\n",
        "\n",
        "1. Create an empty list \"outputs\" to save the outputs of the LSTM Cell at every time step.\n",
        "2. Loop for $t \\in 1, \\ldots, T_x$:\n",
        "\n",
        "    A. Select the \"t\"th time-step vector from X (the shape should be (78,)). To do so, create a custom [Lambda](https://keras.io/layers/core/#lambda) layer in Keras:\n",
        "```    \n",
        "           x = Lambda(lambda x: X[:,t,:])(X)\n",
        "``` \n",
        "Look over the Keras documentation to figure out what this does. It is creating a \"temporary\" or \"unnamed\" function (that's what Lambda functions are) that extracts out the appropriate one-hot vector, and making this function a Keras `Layer` object to apply to `X`. \n",
        "\n",
        "    B. Reshape x to be (1,78). You may find the `reshapor()` layer (defined below) helpful.\n",
        "\n",
        "    C. Run x through one step of LSTM_cell. Remember to initialize the LSTM_cell with the previous step's hidden state $a$ and cell state $c$. Use the following formatting:\n",
        "```python\n",
        "a, _, c = LSTM_cell(input_x, initial_state=[previous hidden state, previous cell state])\n",
        "```\n",
        "\n",
        "    D. Propagate the LSTM's output activation value through a dense+softmax layer using `densor`. \n",
        "    \n",
        "    E. Append the predicted value to the list of \"outputs\"\n",
        " \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MJBPffHM_XUy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: djmodel\n",
        "\n",
        "def djmodel(Tx, n_a, n_values):\n",
        "    \"\"\"\n",
        "    Implement the model\n",
        "    \n",
        "    Arguments:\n",
        "    Tx -- length of the sequence in a corpus\n",
        "    n_a -- the number of activations used in our model\n",
        "    n_values -- number of unique values in the music data \n",
        "    \n",
        "    Returns:\n",
        "    model -- a keras model with the \n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model with a shape \n",
        "    X = Input(shape=(Tx, n_values))\n",
        "    \n",
        "    # Define s0, initial hidden state for the decoder LSTM\n",
        "    a0 = Input(shape=(n_a,), name='a0')\n",
        "    c0 = Input(shape=(n_a,), name='c0')\n",
        "    a = a0\n",
        "    c = c0\n",
        "    \n",
        "    ### START CODE HERE ### \n",
        "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
        "    outputs = []\n",
        "    \n",
        "    # Step 2: Loop\n",
        "    for t in range(Tx):\n",
        "        \n",
        "        # Step 2.A: select the \"t\"th time step vector from X. \n",
        "        x = Lambda(lambda x: X[:,t,:])(X)\n",
        "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
        "        x = reshapor(x)\n",
        "        # Step 2.C: Perform one step of the LSTM_cell\n",
        "        a, _, c = LSTM_cell(x, [a, c])   \n",
        "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
        "        out = densor(a)\n",
        "        # Step 2.E: add the output to \"outputs\"\n",
        "        outputs.append(out)\n",
        "        \n",
        "    # Step 3: Create model instance\n",
        "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HiFsuezN_XU0"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following cell to define your model. We will use `Tx=30`, `n_a=64` (the dimension of the LSTM activations), and `n_values=78`.\n",
        "\n",
        "You then need to compile your model to be trained. We will Adam and a categorical cross-entropy loss."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0_hFqBQM_XU2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)\n",
        "\n",
        "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VjaW4gbP_XU4"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, lets initialize `a0` and `c0` for the LSTM's initial state to be zero. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XMCTVMQ0_XU4",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = 60\n",
        "a0 = np.zeros((m, n_a))\n",
        "c0 = np.zeros((m, n_a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SKUEtZ8K_XU5"
      },
      "cell_type": "markdown",
      "source": [
        "Lets now fit the model! We will turn `Y` to a list before doing so, since the cost function expects `Y` to be provided in this format (one list item per time-step). So `list(Y)` is a list with 30 items, where each of the list items is of shape (60,78). Lets train for 100 epochs. This will take a few minutes. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZgJWlzVd_XU6",
        "outputId": "b8dbff4b-3e17-4d18-be53-4035ef6465ef",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3580
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit([X, a0, c0], list(Y), epochs=100)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "60/60 [==============================] - 20s 340ms/step - loss: 125.8134 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.0333 - dense_5_acc_2: 0.0000e+00 - dense_5_acc_3: 0.0667 - dense_5_acc_4: 0.0500 - dense_5_acc_5: 0.0500 - dense_5_acc_6: 0.0500 - dense_5_acc_7: 0.0833 - dense_5_acc_8: 0.0333 - dense_5_acc_9: 0.0333 - dense_5_acc_10: 0.0333 - dense_5_acc_11: 0.0500 - dense_5_acc_12: 0.0833 - dense_5_acc_13: 0.0000e+00 - dense_5_acc_14: 0.0500 - dense_5_acc_15: 0.0333 - dense_5_acc_16: 0.0667 - dense_5_acc_17: 0.0167 - dense_5_acc_18: 0.0333 - dense_5_acc_19: 0.0333 - dense_5_acc_20: 0.0167 - dense_5_acc_21: 0.1000 - dense_5_acc_22: 0.0333 - dense_5_acc_23: 0.1167 - dense_5_acc_24: 0.0667 - dense_5_acc_25: 0.1000 - dense_5_acc_26: 0.0333 - dense_5_acc_27: 0.0667 - dense_5_acc_28: 0.0500 - dense_5_acc_29: 0.0000e+00                                                                          \n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 122.5675 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0333 - dense_5_acc_1: 0.0833 - dense_5_acc_2: 0.1667 - dense_5_acc_3: 0.1667 - dense_5_acc_4: 0.2500 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.2000 - dense_5_acc_7: 0.2000 - dense_5_acc_8: 0.1500 - dense_5_acc_9: 0.1667 - dense_5_acc_10: 0.1667 - dense_5_acc_11: 0.1167 - dense_5_acc_12: 0.2167 - dense_5_acc_13: 0.2000 - dense_5_acc_14: 0.1333 - dense_5_acc_15: 0.1333 - dense_5_acc_16: 0.2000 - dense_5_acc_17: 0.1167 - dense_5_acc_18: 0.2000 - dense_5_acc_19: 0.0833 - dense_5_acc_20: 0.1000 - dense_5_acc_21: 0.1500 - dense_5_acc_22: 0.0833 - dense_5_acc_23: 0.1667 - dense_5_acc_24: 0.1167 - dense_5_acc_25: 0.1833 - dense_5_acc_26: 0.1000 - dense_5_acc_27: 0.1833 - dense_5_acc_28: 0.0667 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 116.6499 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.0500 - dense_5_acc_2: 0.2333 - dense_5_acc_3: 0.2000 - dense_5_acc_4: 0.3167 - dense_5_acc_5: 0.0667 - dense_5_acc_6: 0.1333 - dense_5_acc_7: 0.1833 - dense_5_acc_8: 0.1500 - dense_5_acc_9: 0.1000 - dense_5_acc_10: 0.0833 - dense_5_acc_11: 0.0500 - dense_5_acc_12: 0.1500 - dense_5_acc_13: 0.1500 - dense_5_acc_14: 0.1000 - dense_5_acc_15: 0.0667 - dense_5_acc_16: 0.1000 - dense_5_acc_17: 0.1000 - dense_5_acc_18: 0.1333 - dense_5_acc_19: 0.0667 - dense_5_acc_20: 0.0833 - dense_5_acc_21: 0.0833 - dense_5_acc_22: 0.1000 - dense_5_acc_23: 0.0667 - dense_5_acc_24: 0.0333 - dense_5_acc_25: 0.0333 - dense_5_acc_26: 0.0667 - dense_5_acc_27: 0.0667 - dense_5_acc_28: 0.0333 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 113.3097 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0500 - dense_5_acc_1: 0.1000 - dense_5_acc_2: 0.2333 - dense_5_acc_3: 0.2500 - dense_5_acc_4: 0.2500 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.1167 - dense_5_acc_7: 0.1833 - dense_5_acc_8: 0.1333 - dense_5_acc_9: 0.1333 - dense_5_acc_10: 0.1500 - dense_5_acc_11: 0.0500 - dense_5_acc_12: 0.1500 - dense_5_acc_13: 0.1333 - dense_5_acc_14: 0.1000 - dense_5_acc_15: 0.0667 - dense_5_acc_16: 0.1167 - dense_5_acc_17: 0.0500 - dense_5_acc_18: 0.1167 - dense_5_acc_19: 0.0500 - dense_5_acc_20: 0.0167 - dense_5_acc_21: 0.0833 - dense_5_acc_22: 0.0667 - dense_5_acc_23: 0.0667 - dense_5_acc_24: 0.0333 - dense_5_acc_25: 0.0667 - dense_5_acc_26: 0.0333 - dense_5_acc_27: 0.0500 - dense_5_acc_28: 0.0333 - dense_5_acc_29: 0.0000e+00            \n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 109.7789 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0333 - dense_5_acc_1: 0.1667 - dense_5_acc_2: 0.2167 - dense_5_acc_3: 0.2333 - dense_5_acc_4: 0.2167 - dense_5_acc_5: 0.0667 - dense_5_acc_6: 0.1000 - dense_5_acc_7: 0.2000 - dense_5_acc_8: 0.1167 - dense_5_acc_9: 0.1333 - dense_5_acc_10: 0.1667 - dense_5_acc_11: 0.0833 - dense_5_acc_12: 0.1667 - dense_5_acc_13: 0.1667 - dense_5_acc_14: 0.1333 - dense_5_acc_15: 0.1000 - dense_5_acc_16: 0.1167 - dense_5_acc_17: 0.1333 - dense_5_acc_18: 0.1500 - dense_5_acc_19: 0.0500 - dense_5_acc_20: 0.0833 - dense_5_acc_21: 0.1333 - dense_5_acc_22: 0.1167 - dense_5_acc_23: 0.0833 - dense_5_acc_24: 0.0500 - dense_5_acc_25: 0.1500 - dense_5_acc_26: 0.1167 - dense_5_acc_27: 0.1000 - dense_5_acc_28: 0.0333 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 106.7915 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0333 - dense_5_acc_1: 0.2500 - dense_5_acc_2: 0.2500 - dense_5_acc_3: 0.2500 - dense_5_acc_4: 0.2833 - dense_5_acc_5: 0.1000 - dense_5_acc_6: 0.1167 - dense_5_acc_7: 0.2167 - dense_5_acc_8: 0.1667 - dense_5_acc_9: 0.1500 - dense_5_acc_10: 0.1833 - dense_5_acc_11: 0.1167 - dense_5_acc_12: 0.1833 - dense_5_acc_13: 0.2333 - dense_5_acc_14: 0.1667 - dense_5_acc_15: 0.1667 - dense_5_acc_16: 0.2000 - dense_5_acc_17: 0.1167 - dense_5_acc_18: 0.1500 - dense_5_acc_19: 0.1333 - dense_5_acc_20: 0.1333 - dense_5_acc_21: 0.1500 - dense_5_acc_22: 0.1167 - dense_5_acc_23: 0.1667 - dense_5_acc_24: 0.1000 - dense_5_acc_25: 0.2000 - dense_5_acc_26: 0.0833 - dense_5_acc_27: 0.2000 - dense_5_acc_28: 0.1667 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 103.7381 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2500 - dense_5_acc_2: 0.2500 - dense_5_acc_3: 0.2500 - dense_5_acc_4: 0.3167 - dense_5_acc_5: 0.1333 - dense_5_acc_6: 0.1833 - dense_5_acc_7: 0.2333 - dense_5_acc_8: 0.1500 - dense_5_acc_9: 0.1500 - dense_5_acc_10: 0.1667 - dense_5_acc_11: 0.1333 - dense_5_acc_12: 0.2000 - dense_5_acc_13: 0.2500 - dense_5_acc_14: 0.1500 - dense_5_acc_15: 0.1500 - dense_5_acc_16: 0.1833 - dense_5_acc_17: 0.1333 - dense_5_acc_18: 0.1667 - dense_5_acc_19: 0.1000 - dense_5_acc_20: 0.1167 - dense_5_acc_21: 0.1500 - dense_5_acc_22: 0.0500 - dense_5_acc_23: 0.1000 - dense_5_acc_24: 0.1000 - dense_5_acc_25: 0.2167 - dense_5_acc_26: 0.1000 - dense_5_acc_27: 0.1667 - dense_5_acc_28: 0.1333 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 100.2797 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2500 - dense_5_acc_2: 0.2333 - dense_5_acc_3: 0.2167 - dense_5_acc_4: 0.3000 - dense_5_acc_5: 0.1167 - dense_5_acc_6: 0.1333 - dense_5_acc_7: 0.2333 - dense_5_acc_8: 0.1500 - dense_5_acc_9: 0.1333 - dense_5_acc_10: 0.1667 - dense_5_acc_11: 0.1167 - dense_5_acc_12: 0.1500 - dense_5_acc_13: 0.1833 - dense_5_acc_14: 0.2000 - dense_5_acc_15: 0.1500 - dense_5_acc_16: 0.1667 - dense_5_acc_17: 0.1500 - dense_5_acc_18: 0.1500 - dense_5_acc_19: 0.0833 - dense_5_acc_20: 0.1167 - dense_5_acc_21: 0.1833 - dense_5_acc_22: 0.1500 - dense_5_acc_23: 0.1333 - dense_5_acc_24: 0.1333 - dense_5_acc_25: 0.2333 - dense_5_acc_26: 0.1500 - dense_5_acc_27: 0.2167 - dense_5_acc_28: 0.1000 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 96.4576 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2333 - dense_5_acc_2: 0.2333 - dense_5_acc_3: 0.2000 - dense_5_acc_4: 0.2667 - dense_5_acc_5: 0.1167 - dense_5_acc_6: 0.1333 - dense_5_acc_7: 0.2667 - dense_5_acc_8: 0.1167 - dense_5_acc_9: 0.1500 - dense_5_acc_10: 0.1667 - dense_5_acc_11: 0.1000 - dense_5_acc_12: 0.1833 - dense_5_acc_13: 0.2333 - dense_5_acc_14: 0.1667 - dense_5_acc_15: 0.1333 - dense_5_acc_16: 0.2000 - dense_5_acc_17: 0.1333 - dense_5_acc_18: 0.1667 - dense_5_acc_19: 0.1500 - dense_5_acc_20: 0.1333 - dense_5_acc_21: 0.1500 - dense_5_acc_22: 0.1333 - dense_5_acc_23: 0.1000 - dense_5_acc_24: 0.1333 - dense_5_acc_25: 0.3333 - dense_5_acc_26: 0.1333 - dense_5_acc_27: 0.1833 - dense_5_acc_28: 0.1833 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 92.5509 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.1500 - dense_5_acc_2: 0.2167 - dense_5_acc_3: 0.2000 - dense_5_acc_4: 0.2667 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.1500 - dense_5_acc_7: 0.2500 - dense_5_acc_8: 0.1833 - dense_5_acc_9: 0.1667 - dense_5_acc_10: 0.1833 - dense_5_acc_11: 0.1500 - dense_5_acc_12: 0.2167 - dense_5_acc_13: 0.2167 - dense_5_acc_14: 0.2000 - dense_5_acc_15: 0.1833 - dense_5_acc_16: 0.2333 - dense_5_acc_17: 0.1667 - dense_5_acc_18: 0.1667 - dense_5_acc_19: 0.2500 - dense_5_acc_20: 0.1500 - dense_5_acc_21: 0.1667 - dense_5_acc_22: 0.1333 - dense_5_acc_23: 0.1333 - dense_5_acc_24: 0.1500 - dense_5_acc_25: 0.3000 - dense_5_acc_26: 0.1167 - dense_5_acc_27: 0.2000 - dense_5_acc_28: 0.1833 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 88.4060 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.1333 - dense_5_acc_2: 0.2167 - dense_5_acc_3: 0.2000 - dense_5_acc_4: 0.2667 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.1500 - dense_5_acc_7: 0.2500 - dense_5_acc_8: 0.1833 - dense_5_acc_9: 0.1667 - dense_5_acc_10: 0.1500 - dense_5_acc_11: 0.1500 - dense_5_acc_12: 0.2333 - dense_5_acc_13: 0.2667 - dense_5_acc_14: 0.2333 - dense_5_acc_15: 0.1667 - dense_5_acc_16: 0.2000 - dense_5_acc_17: 0.1833 - dense_5_acc_18: 0.1667 - dense_5_acc_19: 0.2167 - dense_5_acc_20: 0.1000 - dense_5_acc_21: 0.2000 - dense_5_acc_22: 0.1833 - dense_5_acc_23: 0.1167 - dense_5_acc_24: 0.1000 - dense_5_acc_25: 0.3333 - dense_5_acc_26: 0.2000 - dense_5_acc_27: 0.2333 - dense_5_acc_28: 0.2000 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 84.7533 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.1333 - dense_5_acc_2: 0.2500 - dense_5_acc_3: 0.2167 - dense_5_acc_4: 0.2333 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.1500 - dense_5_acc_7: 0.2667 - dense_5_acc_8: 0.2167 - dense_5_acc_9: 0.1833 - dense_5_acc_10: 0.2167 - dense_5_acc_11: 0.1500 - dense_5_acc_12: 0.2500 - dense_5_acc_13: 0.2500 - dense_5_acc_14: 0.2833 - dense_5_acc_15: 0.2167 - dense_5_acc_16: 0.2167 - dense_5_acc_17: 0.2667 - dense_5_acc_18: 0.2333 - dense_5_acc_19: 0.2833 - dense_5_acc_20: 0.1667 - dense_5_acc_21: 0.1833 - dense_5_acc_22: 0.1667 - dense_5_acc_23: 0.1167 - dense_5_acc_24: 0.1000 - dense_5_acc_25: 0.3000 - dense_5_acc_26: 0.2333 - dense_5_acc_27: 0.2333 - dense_5_acc_28: 0.1500 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 81.0018 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.1333 - dense_5_acc_2: 0.2500 - dense_5_acc_3: 0.2167 - dense_5_acc_4: 0.2500 - dense_5_acc_5: 0.0833 - dense_5_acc_6: 0.1667 - dense_5_acc_7: 0.2833 - dense_5_acc_8: 0.2167 - dense_5_acc_9: 0.2167 - dense_5_acc_10: 0.2167 - dense_5_acc_11: 0.2167 - dense_5_acc_12: 0.2500 - dense_5_acc_13: 0.2500 - dense_5_acc_14: 0.2833 - dense_5_acc_15: 0.2000 - dense_5_acc_16: 0.3000 - dense_5_acc_17: 0.3333 - dense_5_acc_18: 0.2333 - dense_5_acc_19: 0.2833 - dense_5_acc_20: 0.1833 - dense_5_acc_21: 0.1833 - dense_5_acc_22: 0.1833 - dense_5_acc_23: 0.1333 - dense_5_acc_24: 0.1333 - dense_5_acc_25: 0.3167 - dense_5_acc_26: 0.2167 - dense_5_acc_27: 0.2500 - dense_5_acc_28: 0.2000 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 77.5045 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2000 - dense_5_acc_2: 0.2667 - dense_5_acc_3: 0.2167 - dense_5_acc_4: 0.2500 - dense_5_acc_5: 0.1833 - dense_5_acc_6: 0.1833 - dense_5_acc_7: 0.2500 - dense_5_acc_8: 0.3000 - dense_5_acc_9: 0.2667 - dense_5_acc_10: 0.2167 - dense_5_acc_11: 0.2167 - dense_5_acc_12: 0.2833 - dense_5_acc_13: 0.3500 - dense_5_acc_14: 0.3000 - dense_5_acc_15: 0.2667 - dense_5_acc_16: 0.3500 - dense_5_acc_17: 0.2333 - dense_5_acc_18: 0.2500 - dense_5_acc_19: 0.3000 - dense_5_acc_20: 0.2500 - dense_5_acc_21: 0.2333 - dense_5_acc_22: 0.2333 - dense_5_acc_23: 0.1667 - dense_5_acc_24: 0.1500 - dense_5_acc_25: 0.3333 - dense_5_acc_26: 0.2667 - dense_5_acc_27: 0.3333 - dense_5_acc_28: 0.3333 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 73.7612 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2333 - dense_5_acc_2: 0.2667 - dense_5_acc_3: 0.2333 - dense_5_acc_4: 0.2500 - dense_5_acc_5: 0.2167 - dense_5_acc_6: 0.2500 - dense_5_acc_7: 0.3333 - dense_5_acc_8: 0.3000 - dense_5_acc_9: 0.3833 - dense_5_acc_10: 0.2167 - dense_5_acc_11: 0.2167 - dense_5_acc_12: 0.3500 - dense_5_acc_13: 0.3167 - dense_5_acc_14: 0.3167 - dense_5_acc_15: 0.3000 - dense_5_acc_16: 0.3000 - dense_5_acc_17: 0.3833 - dense_5_acc_18: 0.3000 - dense_5_acc_19: 0.2833 - dense_5_acc_20: 0.3000 - dense_5_acc_21: 0.3167 - dense_5_acc_22: 0.3500 - dense_5_acc_23: 0.2000 - dense_5_acc_24: 0.1833 - dense_5_acc_25: 0.4333 - dense_5_acc_26: 0.3500 - dense_5_acc_27: 0.4333 - dense_5_acc_28: 0.4000 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 70.3070 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2333 - dense_5_acc_2: 0.3000 - dense_5_acc_3: 0.2333 - dense_5_acc_4: 0.3167 - dense_5_acc_5: 0.2500 - dense_5_acc_6: 0.3500 - dense_5_acc_7: 0.4333 - dense_5_acc_8: 0.3333 - dense_5_acc_9: 0.4000 - dense_5_acc_10: 0.2667 - dense_5_acc_11: 0.2333 - dense_5_acc_12: 0.4167 - dense_5_acc_13: 0.4000 - dense_5_acc_14: 0.3500 - dense_5_acc_15: 0.3833 - dense_5_acc_16: 0.3333 - dense_5_acc_17: 0.4000 - dense_5_acc_18: 0.3667 - dense_5_acc_19: 0.3000 - dense_5_acc_20: 0.3167 - dense_5_acc_21: 0.3833 - dense_5_acc_22: 0.4167 - dense_5_acc_23: 0.2833 - dense_5_acc_24: 0.1667 - dense_5_acc_25: 0.4667 - dense_5_acc_26: 0.3833 - dense_5_acc_27: 0.4833 - dense_5_acc_28: 0.5167 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 68.2890 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2333 - dense_5_acc_2: 0.3500 - dense_5_acc_3: 0.2667 - dense_5_acc_4: 0.3000 - dense_5_acc_5: 0.3667 - dense_5_acc_6: 0.3667 - dense_5_acc_7: 0.4333 - dense_5_acc_8: 0.4167 - dense_5_acc_9: 0.4167 - dense_5_acc_10: 0.2833 - dense_5_acc_11: 0.3833 - dense_5_acc_12: 0.4500 - dense_5_acc_13: 0.4167 - dense_5_acc_14: 0.3500 - dense_5_acc_15: 0.4333 - dense_5_acc_16: 0.3833 - dense_5_acc_17: 0.4000 - dense_5_acc_18: 0.4167 - dense_5_acc_19: 0.3667 - dense_5_acc_20: 0.4167 - dense_5_acc_21: 0.4333 - dense_5_acc_22: 0.4167 - dense_5_acc_23: 0.3667 - dense_5_acc_24: 0.1833 - dense_5_acc_25: 0.5167 - dense_5_acc_26: 0.3833 - dense_5_acc_27: 0.4333 - dense_5_acc_28: 0.4833 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 65.3279 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2500 - dense_5_acc_2: 0.3667 - dense_5_acc_3: 0.2833 - dense_5_acc_4: 0.3167 - dense_5_acc_5: 0.4000 - dense_5_acc_6: 0.3833 - dense_5_acc_7: 0.4500 - dense_5_acc_8: 0.4333 - dense_5_acc_9: 0.5167 - dense_5_acc_10: 0.3833 - dense_5_acc_11: 0.2833 - dense_5_acc_12: 0.5000 - dense_5_acc_13: 0.4500 - dense_5_acc_14: 0.3500 - dense_5_acc_15: 0.4167 - dense_5_acc_16: 0.4000 - dense_5_acc_17: 0.4500 - dense_5_acc_18: 0.3833 - dense_5_acc_19: 0.3667 - dense_5_acc_20: 0.4167 - dense_5_acc_21: 0.5000 - dense_5_acc_22: 0.4333 - dense_5_acc_23: 0.4333 - dense_5_acc_24: 0.3333 - dense_5_acc_25: 0.5000 - dense_5_acc_26: 0.4000 - dense_5_acc_27: 0.4167 - dense_5_acc_28: 0.5500 - dense_5_acc_29: 0.0000e+00\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 61.7903 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2833 - dense_5_acc_2: 0.3500 - dense_5_acc_3: 0.2667 - dense_5_acc_4: 0.3167 - dense_5_acc_5: 0.4333 - dense_5_acc_6: 0.4333 - dense_5_acc_7: 0.4500 - dense_5_acc_8: 0.5167 - dense_5_acc_9: 0.5667 - dense_5_acc_10: 0.4667 - dense_5_acc_11: 0.3833 - dense_5_acc_12: 0.5167 - dense_5_acc_13: 0.5000 - dense_5_acc_14: 0.4000 - dense_5_acc_15: 0.4000 - dense_5_acc_16: 0.5167 - dense_5_acc_17: 0.4500 - dense_5_acc_18: 0.4500 - dense_5_acc_19: 0.4500 - dense_5_acc_20: 0.4500 - dense_5_acc_21: 0.5667 - dense_5_acc_22: 0.4833 - dense_5_acc_23: 0.4667 - dense_5_acc_24: 0.3333 - dense_5_acc_25: 0.5167 - dense_5_acc_26: 0.4333 - dense_5_acc_27: 0.5000 - dense_5_acc_28: 0.6000 - dense_5_acc_29: 0.0167\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 58.6772 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2833 - dense_5_acc_2: 0.3667 - dense_5_acc_3: 0.3000 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.4333 - dense_5_acc_6: 0.5500 - dense_5_acc_7: 0.5167 - dense_5_acc_8: 0.5500 - dense_5_acc_9: 0.6000 - dense_5_acc_10: 0.5000 - dense_5_acc_11: 0.5167 - dense_5_acc_12: 0.5333 - dense_5_acc_13: 0.5667 - dense_5_acc_14: 0.5167 - dense_5_acc_15: 0.4833 - dense_5_acc_16: 0.5667 - dense_5_acc_17: 0.4833 - dense_5_acc_18: 0.4667 - dense_5_acc_19: 0.4833 - dense_5_acc_20: 0.4833 - dense_5_acc_21: 0.5833 - dense_5_acc_22: 0.4667 - dense_5_acc_23: 0.4500 - dense_5_acc_24: 0.3167 - dense_5_acc_25: 0.5833 - dense_5_acc_26: 0.3833 - dense_5_acc_27: 0.5333 - dense_5_acc_28: 0.6500 - dense_5_acc_29: 0.0167\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 55.8051 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.2833 - dense_5_acc_2: 0.3667 - dense_5_acc_3: 0.3000 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.4333 - dense_5_acc_6: 0.5667 - dense_5_acc_7: 0.5167 - dense_5_acc_8: 0.5333 - dense_5_acc_9: 0.6000 - dense_5_acc_10: 0.4833 - dense_5_acc_11: 0.5167 - dense_5_acc_12: 0.6000 - dense_5_acc_13: 0.5500 - dense_5_acc_14: 0.5833 - dense_5_acc_15: 0.4667 - dense_5_acc_16: 0.5667 - dense_5_acc_17: 0.5500 - dense_5_acc_18: 0.6500 - dense_5_acc_19: 0.6000 - dense_5_acc_20: 0.5333 - dense_5_acc_21: 0.5333 - dense_5_acc_22: 0.5333 - dense_5_acc_23: 0.5833 - dense_5_acc_24: 0.3667 - dense_5_acc_25: 0.6000 - dense_5_acc_26: 0.5167 - dense_5_acc_27: 0.6333 - dense_5_acc_28: 0.6333 - dense_5_acc_29: 0.0167\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 53.0198 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3000 - dense_5_acc_2: 0.3833 - dense_5_acc_3: 0.3167 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.4833 - dense_5_acc_6: 0.5833 - dense_5_acc_7: 0.5167 - dense_5_acc_8: 0.5667 - dense_5_acc_9: 0.5500 - dense_5_acc_10: 0.4833 - dense_5_acc_11: 0.5333 - dense_5_acc_12: 0.6500 - dense_5_acc_13: 0.5333 - dense_5_acc_14: 0.5167 - dense_5_acc_15: 0.5333 - dense_5_acc_16: 0.6000 - dense_5_acc_17: 0.4833 - dense_5_acc_18: 0.6667 - dense_5_acc_19: 0.5833 - dense_5_acc_20: 0.6000 - dense_5_acc_21: 0.5500 - dense_5_acc_22: 0.5833 - dense_5_acc_23: 0.6500 - dense_5_acc_24: 0.4833 - dense_5_acc_25: 0.6833 - dense_5_acc_26: 0.5833 - dense_5_acc_27: 0.7333 - dense_5_acc_28: 0.6500 - dense_5_acc_29: 0.0167\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 50.0850 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3000 - dense_5_acc_2: 0.3833 - dense_5_acc_3: 0.3167 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.5167 - dense_5_acc_6: 0.5500 - dense_5_acc_7: 0.5167 - dense_5_acc_8: 0.5667 - dense_5_acc_9: 0.6500 - dense_5_acc_10: 0.5500 - dense_5_acc_11: 0.6833 - dense_5_acc_12: 0.6500 - dense_5_acc_13: 0.6500 - dense_5_acc_14: 0.6167 - dense_5_acc_15: 0.5500 - dense_5_acc_16: 0.8000 - dense_5_acc_17: 0.5667 - dense_5_acc_18: 0.6167 - dense_5_acc_19: 0.6333 - dense_5_acc_20: 0.5500 - dense_5_acc_21: 0.6500 - dense_5_acc_22: 0.6000 - dense_5_acc_23: 0.7000 - dense_5_acc_24: 0.5167 - dense_5_acc_25: 0.6667 - dense_5_acc_26: 0.5833 - dense_5_acc_27: 0.7167 - dense_5_acc_28: 0.7333 - dense_5_acc_29: 0.0167\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 47.8743 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3000 - dense_5_acc_2: 0.3833 - dense_5_acc_3: 0.3000 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.5167 - dense_5_acc_6: 0.6167 - dense_5_acc_7: 0.5833 - dense_5_acc_8: 0.6167 - dense_5_acc_9: 0.7000 - dense_5_acc_10: 0.5833 - dense_5_acc_11: 0.7167 - dense_5_acc_12: 0.7167 - dense_5_acc_13: 0.6000 - dense_5_acc_14: 0.6500 - dense_5_acc_15: 0.6500 - dense_5_acc_16: 0.8167 - dense_5_acc_17: 0.6333 - dense_5_acc_18: 0.6000 - dense_5_acc_19: 0.6333 - dense_5_acc_20: 0.5667 - dense_5_acc_21: 0.7167 - dense_5_acc_22: 0.6500 - dense_5_acc_23: 0.6500 - dense_5_acc_24: 0.5667 - dense_5_acc_25: 0.7167 - dense_5_acc_26: 0.6500 - dense_5_acc_27: 0.6833 - dense_5_acc_28: 0.7833 - dense_5_acc_29: 0.0167\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 45.3376 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3000 - dense_5_acc_2: 0.3833 - dense_5_acc_3: 0.3167 - dense_5_acc_4: 0.4167 - dense_5_acc_5: 0.5667 - dense_5_acc_6: 0.7000 - dense_5_acc_7: 0.6333 - dense_5_acc_8: 0.7167 - dense_5_acc_9: 0.7833 - dense_5_acc_10: 0.6000 - dense_5_acc_11: 0.7167 - dense_5_acc_12: 0.7833 - dense_5_acc_13: 0.6500 - dense_5_acc_14: 0.7667 - dense_5_acc_15: 0.6833 - dense_5_acc_16: 0.8333 - dense_5_acc_17: 0.7500 - dense_5_acc_18: 0.6167 - dense_5_acc_19: 0.6667 - dense_5_acc_20: 0.6167 - dense_5_acc_21: 0.7667 - dense_5_acc_22: 0.7167 - dense_5_acc_23: 0.6833 - dense_5_acc_24: 0.5667 - dense_5_acc_25: 0.7667 - dense_5_acc_26: 0.6667 - dense_5_acc_27: 0.7333 - dense_5_acc_28: 0.8000 - dense_5_acc_29: 0.0167\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 42.8077 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3833 - dense_5_acc_2: 0.4333 - dense_5_acc_3: 0.3167 - dense_5_acc_4: 0.4500 - dense_5_acc_5: 0.6667 - dense_5_acc_6: 0.7500 - dense_5_acc_7: 0.6333 - dense_5_acc_8: 0.7500 - dense_5_acc_9: 0.8833 - dense_5_acc_10: 0.6167 - dense_5_acc_11: 0.7500 - dense_5_acc_12: 0.8167 - dense_5_acc_13: 0.7167 - dense_5_acc_14: 0.7667 - dense_5_acc_15: 0.7000 - dense_5_acc_16: 0.8333 - dense_5_acc_17: 0.8500 - dense_5_acc_18: 0.7000 - dense_5_acc_19: 0.7167 - dense_5_acc_20: 0.7000 - dense_5_acc_21: 0.8167 - dense_5_acc_22: 0.7000 - dense_5_acc_23: 0.7833 - dense_5_acc_24: 0.6167 - dense_5_acc_25: 0.8167 - dense_5_acc_26: 0.7333 - dense_5_acc_27: 0.7000 - dense_5_acc_28: 0.8333 - dense_5_acc_29: 0.0167\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 40.5582 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.4333 - dense_5_acc_3: 0.3667 - dense_5_acc_4: 0.5833 - dense_5_acc_5: 0.7167 - dense_5_acc_6: 0.7833 - dense_5_acc_7: 0.7500 - dense_5_acc_8: 0.7667 - dense_5_acc_9: 0.8667 - dense_5_acc_10: 0.6833 - dense_5_acc_11: 0.8000 - dense_5_acc_12: 0.8833 - dense_5_acc_13: 0.8167 - dense_5_acc_14: 0.7833 - dense_5_acc_15: 0.6667 - dense_5_acc_16: 0.8667 - dense_5_acc_17: 0.8167 - dense_5_acc_18: 0.8167 - dense_5_acc_19: 0.7333 - dense_5_acc_20: 0.8167 - dense_5_acc_21: 0.9000 - dense_5_acc_22: 0.7333 - dense_5_acc_23: 0.7833 - dense_5_acc_24: 0.6833 - dense_5_acc_25: 0.8333 - dense_5_acc_26: 0.8000 - dense_5_acc_27: 0.7833 - dense_5_acc_28: 0.8333 - dense_5_acc_29: 0.0167\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 38.3782 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.4500 - dense_5_acc_3: 0.3667 - dense_5_acc_4: 0.6167 - dense_5_acc_5: 0.7500 - dense_5_acc_6: 0.8167 - dense_5_acc_7: 0.7833 - dense_5_acc_8: 0.7833 - dense_5_acc_9: 0.8667 - dense_5_acc_10: 0.7167 - dense_5_acc_11: 0.8500 - dense_5_acc_12: 0.8833 - dense_5_acc_13: 0.8833 - dense_5_acc_14: 0.8333 - dense_5_acc_15: 0.6667 - dense_5_acc_16: 0.8500 - dense_5_acc_17: 0.8167 - dense_5_acc_18: 0.8167 - dense_5_acc_19: 0.8000 - dense_5_acc_20: 0.8333 - dense_5_acc_21: 0.8500 - dense_5_acc_22: 0.8667 - dense_5_acc_23: 0.8667 - dense_5_acc_24: 0.7500 - dense_5_acc_25: 0.8667 - dense_5_acc_26: 0.8333 - dense_5_acc_27: 0.8000 - dense_5_acc_28: 0.8167 - dense_5_acc_29: 0.0167\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 36.2452 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.5167 - dense_5_acc_3: 0.4167 - dense_5_acc_4: 0.6667 - dense_5_acc_5: 0.7667 - dense_5_acc_6: 0.8667 - dense_5_acc_7: 0.8667 - dense_5_acc_8: 0.8333 - dense_5_acc_9: 0.8667 - dense_5_acc_10: 0.7833 - dense_5_acc_11: 0.8833 - dense_5_acc_12: 0.9000 - dense_5_acc_13: 0.8667 - dense_5_acc_14: 0.8833 - dense_5_acc_15: 0.8167 - dense_5_acc_16: 0.8667 - dense_5_acc_17: 0.8333 - dense_5_acc_18: 0.8500 - dense_5_acc_19: 0.8833 - dense_5_acc_20: 0.8500 - dense_5_acc_21: 0.8833 - dense_5_acc_22: 0.8667 - dense_5_acc_23: 0.8500 - dense_5_acc_24: 0.7333 - dense_5_acc_25: 0.8833 - dense_5_acc_26: 0.8500 - dense_5_acc_27: 0.8500 - dense_5_acc_28: 0.8500 - dense_5_acc_29: 0.0167\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 34.1843 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.5500 - dense_5_acc_3: 0.4667 - dense_5_acc_4: 0.6500 - dense_5_acc_5: 0.7833 - dense_5_acc_6: 0.9000 - dense_5_acc_7: 0.9000 - dense_5_acc_8: 0.8333 - dense_5_acc_9: 0.8833 - dense_5_acc_10: 0.8667 - dense_5_acc_11: 0.9000 - dense_5_acc_12: 0.9167 - dense_5_acc_13: 0.9000 - dense_5_acc_14: 0.8500 - dense_5_acc_15: 0.8833 - dense_5_acc_16: 0.9000 - dense_5_acc_17: 0.9000 - dense_5_acc_18: 0.9167 - dense_5_acc_19: 0.9333 - dense_5_acc_20: 0.9000 - dense_5_acc_21: 0.9167 - dense_5_acc_22: 0.9000 - dense_5_acc_23: 0.8333 - dense_5_acc_24: 0.7667 - dense_5_acc_25: 0.9167 - dense_5_acc_26: 0.8667 - dense_5_acc_27: 0.9000 - dense_5_acc_28: 0.8833 - dense_5_acc_29: 0.0167\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 32.3294 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.5500 - dense_5_acc_3: 0.5167 - dense_5_acc_4: 0.6667 - dense_5_acc_5: 0.8000 - dense_5_acc_6: 0.8833 - dense_5_acc_7: 0.9167 - dense_5_acc_8: 0.8500 - dense_5_acc_9: 0.9000 - dense_5_acc_10: 0.8333 - dense_5_acc_11: 0.9333 - dense_5_acc_12: 0.9500 - dense_5_acc_13: 0.9167 - dense_5_acc_14: 0.8833 - dense_5_acc_15: 0.9333 - dense_5_acc_16: 0.9167 - dense_5_acc_17: 0.9667 - dense_5_acc_18: 0.9167 - dense_5_acc_19: 0.9333 - dense_5_acc_20: 0.9167 - dense_5_acc_21: 0.9167 - dense_5_acc_22: 0.8833 - dense_5_acc_23: 0.8833 - dense_5_acc_24: 0.8167 - dense_5_acc_25: 0.9167 - dense_5_acc_26: 0.8833 - dense_5_acc_27: 0.9000 - dense_5_acc_28: 0.9167 - dense_5_acc_29: 0.0167\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 30.5203 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.5500 - dense_5_acc_3: 0.5667 - dense_5_acc_4: 0.6833 - dense_5_acc_5: 0.8167 - dense_5_acc_6: 0.9000 - dense_5_acc_7: 0.9000 - dense_5_acc_8: 0.8667 - dense_5_acc_9: 0.9167 - dense_5_acc_10: 0.8667 - dense_5_acc_11: 0.9333 - dense_5_acc_12: 0.9667 - dense_5_acc_13: 0.9333 - dense_5_acc_14: 0.9667 - dense_5_acc_15: 0.9667 - dense_5_acc_16: 0.9500 - dense_5_acc_17: 0.9833 - dense_5_acc_18: 0.9333 - dense_5_acc_19: 0.9500 - dense_5_acc_20: 0.9333 - dense_5_acc_21: 0.9667 - dense_5_acc_22: 0.9333 - dense_5_acc_23: 0.9333 - dense_5_acc_24: 0.8500 - dense_5_acc_25: 0.9167 - dense_5_acc_26: 0.9167 - dense_5_acc_27: 0.9167 - dense_5_acc_28: 0.9000 - dense_5_acc_29: 0.0167\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 28.7667 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.6000 - dense_5_acc_3: 0.6167 - dense_5_acc_4: 0.7500 - dense_5_acc_5: 0.8333 - dense_5_acc_6: 0.9333 - dense_5_acc_7: 0.9500 - dense_5_acc_8: 0.9000 - dense_5_acc_9: 0.9333 - dense_5_acc_10: 0.8833 - dense_5_acc_11: 0.9500 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 0.9333 - dense_5_acc_14: 0.9833 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9667 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 0.9833 - dense_5_acc_19: 0.9333 - dense_5_acc_20: 0.9500 - dense_5_acc_21: 0.9833 - dense_5_acc_22: 0.9500 - dense_5_acc_23: 0.9667 - dense_5_acc_24: 0.9000 - dense_5_acc_25: 0.9333 - dense_5_acc_26: 0.9167 - dense_5_acc_27: 0.9500 - dense_5_acc_28: 0.9167 - dense_5_acc_29: 0.0167\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 27.1444 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.3667 - dense_5_acc_2: 0.6167 - dense_5_acc_3: 0.6167 - dense_5_acc_4: 0.7833 - dense_5_acc_5: 0.8500 - dense_5_acc_6: 0.9333 - dense_5_acc_7: 0.9667 - dense_5_acc_8: 0.9167 - dense_5_acc_9: 0.9667 - dense_5_acc_10: 0.9167 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 0.9333 - dense_5_acc_14: 0.9833 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9667 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 0.9833 - dense_5_acc_19: 0.9500 - dense_5_acc_20: 0.9667 - dense_5_acc_21: 0.9833 - dense_5_acc_22: 0.9667 - dense_5_acc_23: 0.9667 - dense_5_acc_24: 0.9000 - dense_5_acc_25: 0.9500 - dense_5_acc_26: 0.9333 - dense_5_acc_27: 0.9500 - dense_5_acc_28: 0.9333 - dense_5_acc_29: 0.0167\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 25.6229 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.4167 - dense_5_acc_2: 0.5833 - dense_5_acc_3: 0.6167 - dense_5_acc_4: 0.7833 - dense_5_acc_5: 0.8500 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9667 - dense_5_acc_8: 0.9333 - dense_5_acc_9: 0.9833 - dense_5_acc_10: 0.9167 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9667 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 0.9500 - dense_5_acc_20: 0.9667 - dense_5_acc_21: 0.9833 - dense_5_acc_22: 0.9833 - dense_5_acc_23: 0.9667 - dense_5_acc_24: 0.9667 - dense_5_acc_25: 0.9667 - dense_5_acc_26: 0.9667 - dense_5_acc_27: 0.9667 - dense_5_acc_28: 0.9500 - dense_5_acc_29: 0.0167\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 24.2071 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.4167 - dense_5_acc_2: 0.6667 - dense_5_acc_3: 0.6167 - dense_5_acc_4: 0.8000 - dense_5_acc_5: 0.9167 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9667 - dense_5_acc_8: 0.9667 - dense_5_acc_9: 0.9833 - dense_5_acc_10: 0.9500 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9667 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 0.9833 - dense_5_acc_19: 0.9833 - dense_5_acc_20: 0.9667 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 0.9833 - dense_5_acc_25: 0.9500 - dense_5_acc_26: 0.9833 - dense_5_acc_27: 0.9667 - dense_5_acc_28: 0.9333 - dense_5_acc_29: 0.0167\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 22.8532 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.0667 - dense_5_acc_1: 0.4167 - dense_5_acc_2: 0.6833 - dense_5_acc_3: 0.6333 - dense_5_acc_4: 0.8000 - dense_5_acc_5: 0.9333 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 0.9667 - dense_5_acc_9: 0.9833 - dense_5_acc_10: 0.9667 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9833 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 0.9833 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 0.9833 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9667 - dense_5_acc_29: 0.0167\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 21.6624 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4167 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.7167 - dense_5_acc_4: 0.8000 - dense_5_acc_5: 0.9500 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 0.9667 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9667 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9833 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 0.9833 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9667 - dense_5_acc_29: 0.0167\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 20.5163 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4167 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.7500 - dense_5_acc_4: 0.8167 - dense_5_acc_5: 0.9500 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 0.9667 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9667 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 0.9833 - dense_5_acc_20: 0.9667 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 0.9833 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9667 - dense_5_acc_29: 0.0167\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 19.4496 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4333 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.7667 - dense_5_acc_4: 0.8667 - dense_5_acc_5: 0.9500 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 0.9833 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 0.9833 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 0.9833 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 0.9833 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9667 - dense_5_acc_29: 0.0167\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 18.4704 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4333 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.7833 - dense_5_acc_4: 0.9000 - dense_5_acc_5: 0.9500 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9833 - dense_5_acc_29: 0.0500\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 17.5405 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4500 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.7833 - dense_5_acc_4: 0.9000 - dense_5_acc_5: 0.9667 - dense_5_acc_6: 0.9667 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9833 - dense_5_acc_29: 0.0500\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 16.6757 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.7167 - dense_5_acc_3: 0.8167 - dense_5_acc_4: 0.9000 - dense_5_acc_5: 0.9667 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 0.9833 - dense_5_acc_29: 0.0500\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 15.9265 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4667 - dense_5_acc_2: 0.7333 - dense_5_acc_3: 0.8667 - dense_5_acc_4: 0.9000 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 15.1832 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4667 - dense_5_acc_2: 0.7333 - dense_5_acc_3: 0.9000 - dense_5_acc_4: 0.9167 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 0.9833 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 14.5356 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4667 - dense_5_acc_2: 0.7500 - dense_5_acc_3: 0.9000 - dense_5_acc_4: 0.9167 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 13.9471 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.7500 - dense_5_acc_3: 0.9000 - dense_5_acc_4: 0.9500 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 13.3844 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.7500 - dense_5_acc_3: 0.9167 - dense_5_acc_4: 0.9667 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 0.9833 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 12.8815 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.7667 - dense_5_acc_3: 0.9167 - dense_5_acc_4: 0.9667 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 12.4086 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.7667 - dense_5_acc_3: 0.9333 - dense_5_acc_4: 0.9667 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 11.9917 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8000 - dense_5_acc_3: 0.9333 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 11.6057 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9500 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 11.2408 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9500 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 0.9833 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 10.9111 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9500 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 10.6076 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9667 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 0.9833 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 10.3256 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9667 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 10.0703 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 0.9667 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.8291 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.6090 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8333 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.4050 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 0.9833 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.2140 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.4833 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 9.0391 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5167 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.8668 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5167 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.7120 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5500 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.5666 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5500 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.4299 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5667 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.3022 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.5667 - dense_5_acc_2: 0.8500 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.1811 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8667 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 8.0676 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8667 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.9593 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8667 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.8567 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8667 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.7609 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8833 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.6685 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.8833 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.5802 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.4997 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.4179 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.3441 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.2710 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.2030 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.1361 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6167 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.0725 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 7.0105 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.9524 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9000 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.8956 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.8417 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.7893 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.7404 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.6911 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.6444 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.5974 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.5532 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.5130 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6333 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.4690 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6500 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.4283 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6500 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.3900 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6500 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.3522 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6667 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.3158 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6667 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.2792 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6667 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.2435 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6667 - dense_5_acc_2: 0.9167 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 6.2111 - dense_5_loss: 0.0000e+00 - dense_5_acc: 0.1000 - dense_5_acc_1: 0.6667 - dense_5_acc_2: 0.9333 - dense_5_acc_3: 1.0000 - dense_5_acc_4: 1.0000 - dense_5_acc_5: 1.0000 - dense_5_acc_6: 1.0000 - dense_5_acc_7: 1.0000 - dense_5_acc_8: 1.0000 - dense_5_acc_9: 1.0000 - dense_5_acc_10: 1.0000 - dense_5_acc_11: 1.0000 - dense_5_acc_12: 1.0000 - dense_5_acc_13: 1.0000 - dense_5_acc_14: 1.0000 - dense_5_acc_15: 1.0000 - dense_5_acc_16: 1.0000 - dense_5_acc_17: 1.0000 - dense_5_acc_18: 1.0000 - dense_5_acc_19: 1.0000 - dense_5_acc_20: 1.0000 - dense_5_acc_21: 1.0000 - dense_5_acc_22: 1.0000 - dense_5_acc_23: 1.0000 - dense_5_acc_24: 1.0000 - dense_5_acc_25: 1.0000 - dense_5_acc_26: 1.0000 - dense_5_acc_27: 1.0000 - dense_5_acc_28: 1.0000 - dense_5_acc_29: 0.0500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91b1d2b5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Qh5z5g4-_XU7"
      },
      "cell_type": "markdown",
      "source": [
        "You have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music! "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oifcifTVCQzT"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 - Generating music\n",
        "\n",
        "You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. \n",
        "\n",
        "#### 3.1 - Predicting & Sampling"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1dQ63-zi_A0C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(\"images/music_gen.png\",width=900,height=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ANmEdx10_XU8"
      },
      "cell_type": "markdown",
      "source": [
        "At each step of sampling, you will take as input the activation `a` and cell state `c` from the previous state of the LSTM, forward propagate by one step, and *get* a new output activation as well as cell state. The new activation `a` can then be used to generate the output, using `densor` as before. \n",
        "\n",
        "Initialize `x0` as well as the LSTM activation and and cell value `a0` and `c0` to be zeros. \n",
        "\n",
        "\n",
        "<!-- \n",
        "You are about to build a function that will do this inference for you. Your function takes in your previous model and the number of time steps `Ty` that you want to sample. It will return a keras model that would be able to generate sequences for you. Furthermore, the function takes in a dense layer of `78` units and the number of activations. \n",
        "!--> \n",
        "\n",
        "\n",
        "**Exercise:** Implement the function below to sample a sequence of musical values. Here are some of the key steps: \n",
        "\n",
        "Step 2.A: Use `LSTM_Cell`, which inputs the previous step's `c` and `a` to generate the current step's `c` and `a`. \n",
        "\n",
        "Step 2.B: Use `densor` (defined previously) to compute a softmax on `a` to get the output for the current step. \n",
        "\n",
        "Step 2.C: Save the output you have just generated by appending it to `outputs`.\n",
        "\n",
        "Step 2.D: Sample x to the be \"out\"'s one-hot version (the prediction) so that you can pass it to the next LSTM's step.  We have already provided this line of code, which uses a [Lambda](https://keras.io/layers/core/#lambda) function. \n",
        "```python\n",
        "x = Lambda(one_hot)(out) \n",
        "```\n",
        "[Minor technical note: Rather than sampling a value at random according to the probabilities in `out`, this line of code actually chooses the single most likely note at each step using an argmax.]\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q-EMKBLa_XU8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: music_inference_model\n",
        "\n",
        "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
        "    \"\"\"\n",
        "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
        "    \n",
        "    Arguments:\n",
        "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
        "    densor -- the trained \"densor\" from model(), Keras layer object\n",
        "    n_values -- integer, umber of unique values\n",
        "    n_a -- number of units in the LSTM_cell\n",
        "    Ty -- integer, number of time steps to generate\n",
        "    \n",
        "    Returns:\n",
        "    inference_model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model with a shape \n",
        "    x0 = Input(shape=(1, n_values))\n",
        "    \n",
        "    # Define s0, initial hidden state for the decoder LSTM\n",
        "    a0 = Input(shape=(n_a,), name='a0')\n",
        "    c0 = Input(shape=(n_a,), name='c0')\n",
        "    a = a0\n",
        "    c = c0\n",
        "    x = x0\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
        "    outputs = []\n",
        "    \n",
        "    # Step 2: Loop over Ty and generate a value at every time step\n",
        "    for t in range(Ty):\n",
        "        \n",
        "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
        "        a, _, c = LSTM_cell(x, initial_state=[a, c]) \n",
        "        \n",
        "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
        "        out = densor(a)\n",
        "\n",
        "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
        "        outputs.append(out)\n",
        "        \n",
        "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
        "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
        "        #           the line of code you need to do this. \n",
        "        x = Lambda(one_hot)(out)\n",
        "        \n",
        "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
        "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return inference_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YjC7agYB_XU-"
      },
      "cell_type": "markdown",
      "source": [
        "Run the cell below to define your inference model. This model is hard coded to generate 50 values."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XfJqCVYN_XU-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4mLB0ZvF_XU_"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, this creates the zero-valued vectors you will use to initialize `x` and the LSTM state variables `a` and `c`. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H-hjYI7i_XVA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_initializer = np.zeros((1, 1, 78))\n",
        "a_initializer = np.zeros((1, n_a))\n",
        "c_initializer = np.zeros((1, n_a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OPbPboS__XVB"
      },
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Implement `predict_and_sample()`. This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. In order to predict the output corresponding to this input, you will need to carry-out 3 steps:\n",
        "1. Use your inference model to predict an output given your set of inputs. The output `pred` should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).\n",
        "2. Convert `pred` into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the `argmax` of an element of the `pred` list. [Hint](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html).\n",
        "3. Convert the indices into their one-hot vector representations. [Hint](https://keras.io/utils/#to_categorical)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j-ybXs6l_XVB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: predict_and_sample\n",
        "\n",
        "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
        "                       c_initializer = c_initializer):\n",
        "    \"\"\"\n",
        "    Predicts the next value of values using the inference model.\n",
        "    \n",
        "    Arguments:\n",
        "    inference_model -- Keras model instance for inference time\n",
        "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
        "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
        "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
        "    \n",
        "    Returns:\n",
        "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
        "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
        "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
        "    print('Number of outputs: %s' % str(len(pred)))\n",
        "    print('Shape prob per time: %s' % str(pred[0].shape))\n",
        "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
        "    indices = np.argmax(pred, axis=2)\n",
        "    print('Print shape, index per time sample: %s' % str(indices.shape))\n",
        "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
        "    print('Print value for 0: %s' % str(indices[0]))\n",
        "    results = to_categorical(indices)\n",
        "    print('Print value for 0, one-hot: %s' % str(results[0]))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return results, indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EqAdc1Iv_XVC",
        "outputId": "963f7b6a-855c-47a1-8766-66e1f4e01c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
        "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
        "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
        "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of outputs: 50\n",
            "Shape prob per time: (1, 78)\n",
            "Print shape, index per time sample: (50, 1)\n",
            "Print value for 0: [36]\n",
            "Print value for 0, one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "np.argmax(results[12]) = 16\n",
            "np.argmax(results[17]) = 10\n",
            "list(indices[12:18]) = [array([16]), array([10]), array([14]), array([23]), array([16]), array([10])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KMl8M2sx_XVD"
      },
      "cell_type": "markdown",
      "source": [
        "**Expected Output**: Your results may differ because Keras' results are not completely predictable. However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above, you should very likely observe a sequence of indices that are not all identical. Moreover, you should observe that: np.argmax(results[12]) is the first element of list(indices[12:18]) and np.argmax(results[17]) is the last element of list(indices[12:18]). \n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **np.argmax(results[12])** =\n",
        "        </td>\n",
        "        <td>\n",
        "        1\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **np.argmax(results[12])** =\n",
        "        </td>\n",
        "        <td>\n",
        "        42\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **list(indices[12:18])** =\n",
        "        </td>\n",
        "        <td>\n",
        "            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i1l6B37q_XVE"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.3 - Generate music \n",
        "\n",
        "Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your `predict_and_sample()` function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). \n",
        "\n",
        "Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so lets use it in our implementation as well. \n",
        "\n",
        "Lets make some music! "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2hh4_GDM_XVE"
      },
      "cell_type": "markdown",
      "source": [
        "Run the following cell to generate music and record it into your `out_stream`. This can take a couple of minutes."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "depuob5C_XVE",
        "outputId": "6e2459ed-e9fe-4eac-abf1-ec100f8c7881",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "out_stream = generate_music(inference_model)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting new values for different set of chords.\n",
            "Generated 51 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
            "Generated 51 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
            "Generated 50 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
            "Generated 51 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
            "Generated 51 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
            "Your generated music is saved in output/my_music.midi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W2aQ6Zaz_XVG"
      },
      "cell_type": "markdown",
      "source": [
        "Download \"my_music.midi\" in the \"output\" to listen to your music.\n",
        "\n",
        "As reference, listen to \"/data/30s_trained_model.mp3\""
      ]
    }
  ]
}